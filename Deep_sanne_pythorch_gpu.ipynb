{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816293b8-3b43-42fc-9bd3-25edf6b18ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as data_utils\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import psutil # or import multiprocessing\n",
    "\n",
    "annoying_print = False\n",
    "do_print_to_file = True\n",
    "\n",
    "total_cpus = psutil.cpu_count()\n",
    "\n",
    "seed = 4734\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(42) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6890a29-438f-4e78-893d-4ece6f04e467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Número de GPUs disponibles: 4\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f'Número de GPUs disponibles: {num_gpus}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf7fafb-65c3-4538-b989-ad43e65ce5ff",
   "metadata": {},
   "source": [
    "### DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93aa269-2322-47f4-ad72-0029b53d9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos numpy normalizados - imagenes y velocidades\n",
    "\n",
    "# Rutas de trabajo\n",
    "npy_folder = '/disk2/alma/tesisSpace/'\n",
    "numpy_file_name_image = \"numpyFile_simulation_images_real\"\n",
    "numpy_file_name_velocity_x = \"./numpyFile_simulation_velocity_x_real\"\n",
    "numpy_file_name_velocity_y = \"./numpyFile_simulation_velocity_y_real\"\n",
    "numpy_file_name_coordinates = \"./numpyFile_simulation_velocity_coordinates\"\n",
    "\n",
    "def load_normalize_data():\n",
    "    \n",
    "    # Mensaje de depuración\n",
    "    print(\"Ready to load NUMPY images_normalize from \" + npy_folder)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Carga del archivo de imagenes\n",
    "    try:\n",
    "        data_norm_img = np.load(npy_folder + numpy_file_name_image + \".npy\", mmap_mode=None)\n",
    "    except:\n",
    "        print(\"ERROR loading file: \" + npy_folder + numpy_file_name_image + \".npy\")\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"The file \" + npy_folder + numpy_file_name_image + \".npy was loaded.\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # Carga del archivo de velocidades por el momento se toman velocidades verticales y horizontales por separado (Velocidades del dust1)\n",
    "\n",
    "    try:\n",
    "        data_norm_vx = np.load(npy_folder + numpy_file_name_velocity_x + \".npy\", mmap_mode=None)\n",
    "    except:\n",
    "        print(\"ERROR loading file: \" + npy_folder + numpy_file_name_velocity_x + \".npy\")\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"The file \" + npy_folder + numpy_file_name_velocity_x + \".npy was loaded.\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    try:\n",
    "        data_norm_vy = np.load(npy_folder + numpy_file_name_velocity_y + \".npy\", mmap_mode=None)\n",
    "    except:\n",
    "        print(\"ERROR loading file: \" + npy_folder + numpy_file_name_velocity_y + \".npy\")\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"The file \" + npy_folder + numpy_file_name_velocity_y + \".npy was loaded.\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # Cargar coordenadas X e Y de las velocidades (n, 2, 300, 300) 0 --> X / 1 --> Y\n",
    "    try:\n",
    "        data_coordinates_v = np.load(npy_folder + numpy_file_name_coordinates + \".npy\", mmap_mode=None)\n",
    "    except:\n",
    "        print(\"ERROR loading file: \" + npy_folder + numpy_file_name_coordinates + \".npy\")\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"The file \" + npy_folder + numpy_file_name_coordinates + \".npy was loaded.\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    \n",
    "    # Retorno de las matrices numpy\n",
    "    return data_norm_img, data_norm_vx, data_norm_vy, data_coordinates_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae1a6d9-7f35-4ceb-a416-36bb0c2e0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa conjunto de entrenamiento, validacion y test considerando imagenes, velcoidades en x, velocidades en y\n",
    "# y coordinadas de velcidades X e Y (en un mismo arreglo (n, 2, npix, npix)). Luego de esta funcion se debe selecionar\n",
    "# con que velocidades se quiere trabajar el modelo. Las coordenadas estan porsi se quiere graficar o estudiar las velocidades\n",
    "# obtenidas.\n",
    "def adapt_training_data_PyTorch(data_img_norm, data_vel_norm_vx, data_vel_norm_vy, data_coordinates):\n",
    "    print(\"\\n ADAPTING DATA FOR PYTORCH___________________________\")\n",
    "    \n",
    "    # Imprimir detalles iniciales del array de datos\n",
    "    print(\"I1 dtype =\", data_img_norm.dtype, \"- shape =\", data_img_norm.shape)\n",
    "    print(\"Vx1 dtype =\", data_vel_norm_vx.dtype, \"- shape =\", data_vel_norm_vx.shape)\n",
    "    print(\"Vy1 dtype =\", data_vel_norm_vy.dtype, \"- shape =\", data_vel_norm_vy.shape)\n",
    "    print(\"Coordinates dtype =\", data_coordinates.dtype, \"- shape =\", data_coordinates.shape)\n",
    "    \n",
    "    # Expandir el array de imágenes para incluir el canal como una dimensión adicional\n",
    "    # (batch_size, time_step, pix, pix) ---> (batch_size, time_step, pix, pix, 1)\n",
    "    data_img_norm = np.expand_dims(data_img_norm, axis=4)\n",
    "    print(\"I2 dtype =\", data_img_norm.dtype, \"- shape =\", data_img_norm.shape)\n",
    "\n",
    "    # Expandir el array de velocidades para incluir el canal como una dimensión adicional\n",
    "    # (batch_size, pix, pix) ---> (batch_size, pix, pix, 1)\n",
    "    data_vel_norm_vx = np.expand_dims(data_vel_norm_vx, axis=3)\n",
    "    print(\"xV2 dtype =\", data_vel_norm_vx.dtype, \"- shape =\", data_vel_norm_vx.shape)\n",
    "\n",
    "    data_vel_norm_vy = np.expand_dims(data_vel_norm_vy, axis=3)\n",
    "    print(\"Vy2 dtype =\", data_vel_norm_vy.dtype, \"- shape =\", data_vel_norm_vy.shape)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    print(\"READY TO SELECT IMAGES TO TRAIN, VALIDATE & TEST______________________\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Inicialización de listas de índices\n",
    "    random_list_indexes_train = []\n",
    "    random_list_indexes_valid = []\n",
    "    random_list_indexes_test = []\n",
    "    \n",
    "    total_data_len = data_img_norm.shape[0]\n",
    "\n",
    "    # Crear índices para dividir los datos\n",
    "    indices = np.arange(total_data_len)\n",
    "    \n",
    "    # Dividir los datos en conjuntos de entrenamiento + validación y prueba\n",
    "    random_indexes_valid, random_indexes_test = train_test_split(\n",
    "        indices, test_size=0.05, random_state=23)\n",
    "    \n",
    "    # Dividir los datos de entrenamiento + validación en entrenamiento y validación\n",
    "    random_indexes_train, random_indexes_valid = train_test_split(\n",
    "        random_indexes_valid, test_size=0.4, random_state=23)\n",
    "    \n",
    "    # Selección de imágenes para los conjuntos de entrenamiento, validación y prueba\n",
    "    train_images = data_img_norm[random_indexes_train, :, :, :]\n",
    "    valid_images = data_img_norm[random_indexes_valid, :, :, :]\n",
    "    test_images = data_img_norm[random_indexes_test, :, :, :]\n",
    "    print(\"Train_images dtype =\", train_images.dtype, \"- shape =\", train_images.shape)\n",
    "    print(\"Valid_images =\", valid_images.dtype, \"- shape =\", valid_images.shape)\n",
    "    print(\"Test_images =\", test_images.dtype, \"- shape =\", test_images.shape)\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Separar velocidades en x\n",
    "    train_velocity_vx = data_vel_norm_vx[random_indexes_train, :, :, :]\n",
    "    valid_velocity_vx = data_vel_norm_vx[random_indexes_valid, :, :, :]\n",
    "    test_velocity_vx = data_vel_norm_vx[random_indexes_test, :, :, :]\n",
    "    print(\"Train_velocity x dtype =\", train_velocity_vx.dtype, \"- shape =\", train_velocity_vx.shape)\n",
    "    print(\"Valid_velocity x dtype =\", valid_velocity_vx.dtype, \"- shape =\", valid_velocity_vx.shape)\n",
    "    print(\"Test_velocity x dtype =\", test_velocity_vx.dtype, \"- shape =\", test_velocity_vx.shape)\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Separar velocidades en y\n",
    "    train_velocity_vy = data_vel_norm_vy[random_indexes_train, :, :, :]\n",
    "    valid_velocity_vy = data_vel_norm_vy[random_indexes_valid, :, :, :]\n",
    "    test_velocity_vy = data_vel_norm_vy[random_indexes_test, :, :, :]\n",
    "    print(\"Train_velocity y dtype =\", train_velocity_vy.dtype, \"- shape =\", train_velocity_vy.shape)\n",
    "    print(\"Valid_velocity y dtype =\", valid_velocity_vy.dtype, \"- shape =\", valid_velocity_vy.shape)\n",
    "    print(\"Test_velocity y dtype =\", test_velocity_vy.dtype, \"- shape =\", test_velocity_vy.shape)\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Separar coordenadas de velocidades\n",
    "    train_coordinates = data_coordinates[random_indexes_train, :, :, :]\n",
    "    valid_coordinates = data_coordinates[random_indexes_valid, :, :, :]\n",
    "    test_coordinates = data_coordinates[random_indexes_test, :, :, :]\n",
    "    print(\"Train_coordinates dtype =\", train_coordinates.dtype, \"- shape =\", train_coordinates.shape)\n",
    "    print(\"Valid_coordinates dtype =\", valid_coordinates.dtype, \"- shape =\", valid_coordinates.shape)\n",
    "    print(\"Test_coordinates dtype =\", test_coordinates.dtype, \"- shape =\", test_coordinates.shape)\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # No hay etiquetas, así que solo se devuelven las imágenes\n",
    "    return train_images, valid_images, test_images, train_velocity_vx, valid_velocity_vx, test_velocity_vx,\\\n",
    "    train_velocity_vy, valid_velocity_vy, test_velocity_vy, train_coordinates, valid_coordinates, test_coordinates, total_data_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa345b67-2b5e-4475-8eda-2a6b3ca1522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataset para el entrenamiento\n",
    "\n",
    "def prepare_datasets(train_images, valid_images, test_images, train_velocity, valid_velocity, test_velocity, batch_size):\n",
    "\n",
    "    print(\"\\n READY TO PREPARE DATASETS______________________\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Convertir a tensores de PyTorch\n",
    "    torch_Tensor_train_images = torch.FloatTensor(train_images)\n",
    "    torch_Tensor_valid_images = torch.FloatTensor(valid_images)\n",
    "    torch_Tensor_test_images = torch.FloatTensor(test_images)\n",
    "    print( \"Torch_Tensor_train_images.size() = \", torch_Tensor_train_images.size())\n",
    "    print( \"Torch_Tensor_valid_images.size() = \", torch_Tensor_valid_images.size())\n",
    "    print( \"Torch_Tensor_test_images.size() = \", torch_Tensor_test_images.size())\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    torch_Tensor_train_velocitys = torch.FloatTensor(train_velocity)\n",
    "    torch_Tensor_valid_velocitys = torch.FloatTensor(valid_velocity)\n",
    "    torch_Tensor_test_velocitys = torch.FloatTensor(test_velocity)\n",
    "    print( \"Torch_Tensor_train_velocitys.size() = \", torch_Tensor_train_velocitys.size())\n",
    "    print( \"Torch_Tensor_valid_velocitys.size() = \", torch_Tensor_valid_velocitys.size())\n",
    "    print( \"Torch_Tensor_test_velocitys.size() = \", torch_Tensor_test_velocitys.size())\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Crear datasets con ProtoplanetaryDiskDataset\n",
    "    train_dataset =  data_utils.TensorDataset(torch_Tensor_train_images, torch_Tensor_train_velocitys)\n",
    "    valid_dataset = data_utils.TensorDataset(torch_Tensor_valid_images, torch_Tensor_valid_velocitys)\n",
    "    test_dataset = data_utils.TensorDataset(torch_Tensor_test_images, torch_Tensor_test_velocitys)\n",
    "    print( \"Train_dataset = \", train_dataset)\n",
    "    print( \"Valid_dataset = \", valid_dataset)\n",
    "    print( \"Test_dataset = \", test_dataset)\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Crear dataloaders\n",
    "    train_dataloader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    valid_dataloader = data_utils.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_dataloader = data_utils.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    print( \"Train_dataloader = \", train_dataloader)\n",
    "    print( \"Valid_dataloader = \", valid_dataloader)\n",
    "    print( \"Test_dataloader = \", test_dataloader)\n",
    "    print(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    return train_dataloader, valid_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389f5fe-7c74-441c-a03d-9bfb903f5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar datos\n",
    "\n",
    "#Cargar datos (batch_size, time_step, pix, pix) image\n",
    "data_img_norm, data_vx_norm, data_vy_norm, data_coordinates = load_normalize_data()\n",
    "\n",
    "num_img = 263\n",
    "pix_prueba = 300\n",
    "batch = 2\n",
    "start_step = 5\n",
    "end_step = 19\n",
    "time_steps = end_step - start_step\n",
    "\n",
    "data_img_norm = data_img_norm[0:num_img, start_step:end_step, 0:pix_prueba, 0:pix_prueba]\n",
    "data_vy_norm = data_vy_norm[0:num_img, 0:pix_prueba, 0:pix_prueba]\n",
    "\n",
    "print(\"Image Shape\", data_img_norm.shape)\n",
    "print(\"Image Max: \", data_img_norm.max(), \" Image Min: \", data_img_norm.min())\n",
    "\n",
    "print(\"Vx Shape\", data_vx_norm.shape)\n",
    "print(\"Vx Max: \", data_vx_norm.max(), \" Vx Min: \", data_vx_norm.min())\n",
    "\n",
    "print(\"Vy Shape\", data_vy_norm.shape)\n",
    "print(\"Vy Max: \", data_vy_norm.max(), \" Vy Min: \", data_vy_norm.min())\n",
    "\n",
    "print(\"Coordinates Shape\", data_coordinates.shape)\n",
    "\n",
    "# Adaptar los datos para PyTorch y generar conjuntos de entrenamiento \n",
    "train_images, valid_images, test_images, _, _, _, train_velocity_y, valid_velocity_y, test_velocity_y, _, _, _, batch_size = \\\n",
    "adapt_training_data_PyTorch(data_img_norm, data_vx_norm, data_vy_norm, data_coordinates)\n",
    "\n",
    "\n",
    "# Crear datasets (considerar velocidad que se desee)\n",
    "train_loader, valid_loader, test_loader = prepare_datasets(train_images, valid_images, test_images, train_velocity_y, \n",
    "                                                           valid_velocity_y, test_velocity_y, batch_size=batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107cfe0-c937-46a6-9e0f-2207f0fd7bfb",
   "metadata": {},
   "source": [
    "### MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8017f0-b1d1-4887-ab29-e3049c27cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Densely Layer GPU and Second Densely Layer GPU\n",
    "# Tensor dimension in (batch, time, n, m, channels) out (batch, time, new channels, n, m) (es necesario permutar salida para conv por posicion de channels)\n",
    "# Input parameters:\n",
    "# in_channels, out_channels --> canales de entrada y salida\n",
    "# num_labels --> ver\n",
    "# split_gpus, parallel_data --> bool para evaluar uso de gpu\n",
    "class FirstDenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_labels, split_gpus, parallel_data):\n",
    "        super(FirstDenseLayer, self).__init__()\n",
    "        self.split_gpus = split_gpus\n",
    "        self.parallel_data = parallel_data\n",
    "\n",
    "        input_num_DENSE_01 = \"---\"\n",
    "        print( \"Densely Layer  --- in_channels , out_channels , \"+\\\n",
    "        \"input_num_DENSE_01 , num_labels ===> \" , \\\n",
    "        in_channels , out_channels , input_num_DENSE_01 , num_labels)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        self.linear = nn.Linear(in_channels , out_channels)# 1 layer: in 1 (imagen en escala de grises) / out 64\n",
    "\n",
    "    def forward(self, tensor):\n",
    "\n",
    "        if annoying_print :\n",
    "          print('001 tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        tensor = self.linear(tensor)\n",
    "\n",
    "        if annoying_print :\n",
    "          print('002 tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        tensor = tensor.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "        if annoying_print :\n",
    "          print('003 tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "387e6a19-315e-4798-a11c-d53225cdfbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTMConv2D Layer GPU\n",
    "# Input shape in (batch_size, time_steps, in_channels, height, width) out (batch_size, time_steps, out_channels, height, width)\n",
    "# Input parameters:\n",
    "#input_size = canales de entrada\n",
    "#hidden_size = filters\n",
    "#kernel_size = tamaño del kernel de conv\n",
    "#num_layers = numero de capas lstm\n",
    "#bias = bool para determinar uso de sesgo\n",
    "#output_size = canales de salida\n",
    "#split_gpus, parallel_data = bools para evaluar uso de gpu\n",
    "class Conv2dLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, kernel_size, bias=True):\n",
    "        super(Conv2dLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if isinstance(kernel_size, tuple) and len(kernel_size) == 2:\n",
    "            self.kernel_size = kernel_size\n",
    "        elif isinstance(kernel_size, int):\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid kernel size.\")\n",
    "        \n",
    "        self.padding = self.calculate_padding(self.kernel_size)      \n",
    "\n",
    "        self.bias = bias\n",
    "        self.x2h = nn.Conv2d(in_channels=input_size, out_channels=hidden_size * 4,\n",
    "                             kernel_size=self.kernel_size, padding=self.padding, bias=bias)\n",
    "\n",
    "        self.h2h = nn.Conv2d(in_channels=hidden_size, out_channels=hidden_size * 4,\n",
    "                             kernel_size=self.kernel_size, padding=self.padding, bias=bias)\n",
    "        self.Wc = None\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    # Padding for 'same' output size\n",
    "    def calculate_padding(self, kernel_size):\n",
    "        return (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / np.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        # Inputs:\n",
    "        #       input: of shape (batch_size, input_size, height_size, width_size)\n",
    "        #       hx: of shape (batch_size, hidden_size, height_size, width_size)\n",
    "        # Outputs:\n",
    "        #       hy: of shape (batch_size, hidden_size, height_size, width_size)\n",
    "        #       cy: of shape (batch_size, hidden_size, height_size, width_size)\n",
    "        if annoying_print :\n",
    "            print(\"Input cellLSTMConv: \", input.shape)\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        if self.Wc == None:\n",
    "            if torch.cuda.is_available():\n",
    "                self.Wc = nn.Parameter(torch.zeros(1, self.hidden_size * 3, input.size(-2), input.size(-1), device='cuda:2'))\n",
    "            else:\n",
    "                self.Wc = nn.Parameter(torch.zeros(1, self.hidden_size * 3, input.size(-2), input.size(-1)))\n",
    "            \n",
    "        if hx is None:\n",
    "            if torch.cuda.is_available():\n",
    "                #times_step, out_channeles, w, h \n",
    "                hx = torch.zeros(input.size(0), self.hidden_size, input.size(-2), input.size(-1), device='cuda:2')\n",
    "                hx = (hx, hx)\n",
    "            else:\n",
    "                hx = torch.zeros(input.size(0), self.hidden_size, input.size(-2), input.size(-1))\n",
    "                hx = (hx, hx)                \n",
    "        hx, cx = hx\n",
    "        \n",
    "        gates = self.x2h(input) + self.h2h(hx)\n",
    "\n",
    "        # Get gates (i_t, f_t, g_t, o_t)\n",
    "        input_gate, forget_gate, cell_gate, output_gate = gates.chunk(4, 1)\n",
    "\n",
    "        Wci, Wcf, Wco = self.Wc.chunk(3, 1)\n",
    "\n",
    "        i_t = torch.sigmoid(input_gate + Wci * cx)\n",
    "        f_t = torch.sigmoid(forget_gate + Wcf * cx)\n",
    "        g_t = torch.tanh(cell_gate)\n",
    "\n",
    "        cy = f_t * cx + i_t * torch.tanh(g_t)\n",
    "        o_t = torch.sigmoid(output_gate + Wco * cy)\n",
    "\n",
    "        hy = o_t * torch.tanh(cy)\n",
    "        \n",
    "        return (hy, cy)\n",
    "\n",
    "class Conv2dLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, kernel_size, num_layers, bias, output_size, split_gpus, parallel_data):\n",
    "        super(Conv2dLSTM, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if type(kernel_size) == tuple and len(kernel_size) == 2:\n",
    "            self.kernel_size = kernel_size\n",
    "        elif type(kernel_size) == int:\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid kernel size.\")\n",
    "\n",
    "        self.padding = self.calculate_padding(self.kernel_size)   \n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "        self.split_gpus = split_gpus\n",
    "        self.parallel_data = parallel_data\n",
    "        \n",
    "        input_num_CONV_01 = \"---\"\n",
    "        print( \"LSTMConv Layer  --- filters, kernel_size, padding,  \"+\\\n",
    "        \"input_num_DENSE_01 , num_layers ===> \" , \\\n",
    "        self.hidden_size, kernel_size, self.padding, input_num_CONV_01 , num_layers)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        self.rnn_cell_list = nn.ModuleList()\n",
    "        self.rnn_cell_list.append(Conv2dLSTMCell(self.input_size, self.hidden_size,\n",
    "                                                 self.kernel_size, self.bias))\n",
    "        \n",
    "        for l in range(1, self.num_layers):\n",
    "            self.rnn_cell_list.append(Conv2dLSTMCell(self.hidden_size, self.hidden_size,\n",
    "                                                     self.kernel_size, self.bias))\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.hidden_size, out_channels=self.output_size,\n",
    "                             kernel_size=self.kernel_size, padding=self.padding, bias=self.bias)\n",
    "        \n",
    "    def calculate_padding(self, kernel_size):\n",
    "        return (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "\n",
    "        if annoying_print :\n",
    "          print('001 LSTMConv2D tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          input.device, input.shape, input.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        if hx is None:\n",
    "            if torch.cuda.is_available():\n",
    "                # num_capas, batch_size, times_step, out_channeles, w, h   \n",
    "                h0 = torch.zeros(self.num_layers, input.size(0), self.hidden_size, input.size(-2), input.size(-1), device='cuda:2')\n",
    "            else:\n",
    "                h0 = torch.zeros(self.num_layers, input.size(0), self.hidden_size, input.size(-2), input.size(-1))\n",
    "        else:\n",
    "             h0 = hx\n",
    "        \n",
    "        outs = []\n",
    "        hidden = list()\n",
    "            \n",
    "        # Inicializa los estados ocultos h0 y de celda c0 (mismas dimensiones) para todas las capas \n",
    "        for layer in range(self.num_layers):\n",
    "            hidden.append((h0[layer], h0[layer]))\n",
    "\n",
    "        #Por cada paso de tiempo aplica LSTMConv2D por capa por celda\n",
    "        for t in range(input.size(1)):\n",
    "            for layer in range(self.num_layers):\n",
    "                if layer == 0:\n",
    "                    hidden_l = self.rnn_cell_list[layer](\n",
    "                        input[:, t, :],\n",
    "                        (hidden[layer][0],hidden[layer][1])\n",
    "                        )\n",
    "                else:\n",
    "                    hidden_l = self.rnn_cell_list[layer](\n",
    "                        hidden[layer - 1][0],\n",
    "                        (hidden[layer][0], hidden[layer][1])\n",
    "                        )\n",
    "\n",
    "                hidden[layer] = hidden_l\n",
    "\n",
    "            outs.append(hidden_l[0])\n",
    "\n",
    "        out = outs[-1].squeeze()\n",
    "\n",
    "        out = self.conv(out)\n",
    "\n",
    "        if annoying_print :\n",
    "          print('002 LSTMConv2D tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          out.device, out.shape, out.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        dims = list(range(out.ndim))\n",
    "        dims[-3], dims[-2], dims[-1] = dims[-2], dims[-1], dims[-3]\n",
    "        tensor = out.permute(dims)\n",
    "\n",
    "        if annoying_print :\n",
    "          print('003 LSTMConv2D tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          out.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a2f7a1-0352-4abe-9284-bb69c9483a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Densely Layer GPU and Second Densely Layer GPU\n",
    "# Tensor dimension in (batch, n, m, channels) out (batch, n, m, new channels)\n",
    "# Input parameters:\n",
    "# in_channels, out_channels --> canales de entrada y salida\n",
    "# num_labels --> ver\n",
    "# split_gpus, parallel_data --> bool para evaluar uso de gpu\n",
    "class SecondDenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_labels, split_gpus, parallel_data):\n",
    "        super(SecondDenseLayer, self).__init__()\n",
    "        self.split_gpus = split_gpus\n",
    "        self.parallel_data = parallel_data\n",
    "\n",
    "        input_num_DENSE_01 = \"---\"\n",
    "        print( \"Densely Layer  --- in_channels , out_channels , \"+\\\n",
    "        \"input_num_DENSE_01 , num_labels ===> \" , \\\n",
    "        in_channels , out_channels , input_num_DENSE_01 , num_labels)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        self.linear = nn.Linear(in_channels , out_channels)# 1 layer: in 128 (imagen en escala de grises) / out 128\n",
    "\n",
    "    def forward(self, tensor):\n",
    "\n",
    "        if annoying_print :\n",
    "          print('001 Second tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        tensor = self.linear(tensor)\n",
    "\n",
    "        if annoying_print :\n",
    "          print('002 Second tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a228f1f-f02a-4f42-a2c4-80397ba811a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa extra para prueba\n",
    "class ThridDenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_labels, split_gpus, parallel_data):\n",
    "        super(ThridDenseLayer, self).__init__()\n",
    "        self.split_gpus = split_gpus\n",
    "        self.parallel_data = parallel_data\n",
    "\n",
    "        input_num_DENSE_01 = \"---\"\n",
    "        print( \"Densely Layer  --- in_channels , out_channels , \"+\\\n",
    "        \"input_num_DENSE_01 , num_labels ===> \" , \\\n",
    "        in_channels , out_channels , input_num_DENSE_01 , num_labels)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        self.linear = nn.Linear(in_channels , out_channels)# 1 layer: in 128 (imagen en escala de grises) / out 64\n",
    "\n",
    "    def forward(self, tensor):\n",
    "\n",
    "        if annoying_print :\n",
    "          print('001 Third tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        tensor = self.linear(tensor)\n",
    "\n",
    "        if annoying_print :\n",
    "          print('002 Third tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13b9ee68-96ce-406b-a472-cea2511e544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer GPU\n",
    "# Tensor dimension in (batch, n, m, channels) (toma la ultima salida de lstm) out (batch, n, m)\n",
    "# Input parameters:\n",
    "# in_channels, out_channels --> canales de entrada y salida\n",
    "# num_labels --> ver\n",
    "# split_gpus, parallel_data --> bool para evaluar uso de gpu\n",
    "class OutputDenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_labels, split_gpus, parallel_data):\n",
    "        super(OutputDenseLayer, self).__init__()\n",
    "        self.split_gpus = split_gpus\n",
    "        self.parallel_data = parallel_data\n",
    "\n",
    "        input_num_DENSE_OUT_01 = \"---\"\n",
    "        print( \"Densely Output Layer  --- in_channels , out_channels , \"+\\\n",
    "        \"input_num_DENSE_OUT_01 , num_labels ===> \" , \\\n",
    "        in_channels , out_channels , input_num_DENSE_OUT_01 , num_labels)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        self.linear = nn.Linear(in_channels , out_channels) # in 128 / out 1 -- volver a dimension de entrada (change exo 128 to 64)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "\n",
    "        if annoying_print :\n",
    "          print('001 out tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "\n",
    "        tensor = self.linear(tensor)\n",
    "        \n",
    "        if annoying_print :\n",
    "          print('002 out tensor device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "          tensor.device, tensor.shape, tensor.type()))\n",
    "          sys.stdout.flush()\n",
    "            \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "181b4730-b538-4567-98fe-85c80fc15823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSanne(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepSanne, self).__init__()\n",
    "\n",
    "        channels = 1\n",
    "        self.num_channels = 64\n",
    "        filter = 128\n",
    "        kernel_size = (1,1)\n",
    "        num_labels = 1 \n",
    "        bias = True\n",
    "\n",
    "        self.module0 = FirstDenseLayer(channels, self.num_channels, num_labels, True, False)\n",
    "        self.module1 = Conv2dLSTM(self.num_channels, filter, kernel_size, num_labels, bias, filter, True, False)\n",
    "        self.module2 = SecondDenseLayer(filter, filter, num_labels, True, False)\n",
    "        self.module2_1 = ThridDenseLayer(filter, self.num_channels, num_labels, True, False)\n",
    "        self.module3 = OutputDenseLayer(self.num_channels, 1, num_labels, True, False)\n",
    "        #self.module3 = OutputDenseLayer(filter, 1, num_labels, True, False)\n",
    "\n",
    "    def forward( self, tensor):\n",
    "\n",
    "        print('Input device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "        tensor.device, tensor.shape, tensor.type()))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        tensor = self.module0(tensor)\n",
    "        print('Input after module0 device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "        tensor.device, tensor.shape, tensor.type()))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        tensor = self.module1(tensor)\n",
    "        print('Input after module1 device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "        tensor.device, tensor.shape, tensor.type()))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        tensor = self.module2(tensor)\n",
    "        print('Input after module2 device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "        tensor.device, tensor.shape, tensor.type()))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # expppp\n",
    "        tensor = self.module2_1(tensor)\n",
    "        print('Input after module2 device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "        tensor.device, tensor.shape, tensor.type()))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        tensor = self.module3(tensor)\n",
    "        print('Input after module3 device==> {}, shape==> {}, type==> {}\\n'.format(\\\n",
    "        tensor.device, tensor.shape, tensor.type()))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf84ba2-269d-4a0f-a75b-d1906fee9802",
   "metadata": {},
   "outputs": [],
   "source": [
    " class ModelParallel(DeepSanne) :\n",
    "    def __init__(self, *args, **kwargs):\n",
    "      super(ModelParallel, self).__init__( *args , **kwargs )\n",
    "\n",
    "    # Distibuir tensor layers en cuda\n",
    "      self.seq0 = nn.Sequential(self.module0).to('cuda:0')\n",
    "      self.seq1 = nn.Sequential(self.module1).to('cuda:2')\n",
    "      self.seq2 = nn.Sequential(self.module2).to('cuda:3')\n",
    "      self.seq2_1 = nn.Sequential(self.module2_1).to('cuda:3')\n",
    "      self.seq3 = nn.Sequential(self.module3).to('cuda:3')\n",
    "\n",
    "    def forward(self, tensor):\n",
    "\n",
    "      # Conectar (pasar) resultados entre capas\n",
    "      tensor = self.seq0(tensor).to('cuda:2')\n",
    "      tensor = self.seq1(tensor).to('cuda:3')\n",
    "      tensor = self.seq2(tensor).to('cuda:3')\n",
    "      tensor = self.seq2_1(tensor).to('cuda:3')\n",
    "      tensor = self.seq3(tensor)\n",
    "\n",
    "      return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1ed85-e025-41c0-a2f1-e248a57f5cc2",
   "metadata": {},
   "source": [
    "### ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "806a0413-ef57-4605-8f7e-039ce612d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para liberar memoria antes de empezar\n",
    "def liberar_memoria():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.reset_accumulated_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8239a51b-8502-4594-9e4d-73b222a8f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberar_memoria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d7cda-8672-4e30-8123-d7e018bffd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Densely Layer  --- in_channels , out_channels , input_num_DENSE_01 , num_labels ===>  1 64 --- 1\n",
      "LSTMConv Layer  --- filters, kernel_size, padding,  input_num_DENSE_01 , num_layers ===>  128 (1, 1) (0, 0) --- 1\n",
      "Densely Layer  --- in_channels , out_channels , input_num_DENSE_01 , num_labels ===>  128 128 --- 1\n",
      "Densely Layer  --- in_channels , out_channels , input_num_DENSE_01 , num_labels ===>  128 64 --- 1\n",
      "Densely Output Layer  --- in_channels , out_channels , input_num_DENSE_OUT_01 , num_labels ===>  64 1 --- 1\n",
      "\n",
      " READY TO TRAIN THE MODEL______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|                                                                            | 0/62 [00:00<?, ?batch/s]/disk2/alma/anaconda3/envs/newt/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Epoch 1/10:  98%|███████████████████████████████████████████████▏| 61/62 [01:21<00:01,  1.34s/batch, train_loss=0.0221]/disk2/alma/anaconda3/envs/newt/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1, 300, 300, 1])) that is different to the input size (torch.Size([300, 300, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1/10: 100%|████████████████████████████████████████████████| 62/62 [01:23<00:00,  1.35s/batch, train_loss=0.0131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training RMSE: 0.1765, Validation RMSE: 0.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████| 62/62 [01:22<00:00,  1.33s/batch, train_loss=0.0366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training RMSE: 0.1542, Validation RMSE: 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████████| 62/62 [01:22<00:00,  1.33s/batch, train_loss=0.0227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training RMSE: 0.1539, Validation RMSE: 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████| 62/62 [01:22<00:00,  1.33s/batch, train_loss=0.0147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training RMSE: 0.1537, Validation RMSE: 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████| 62/62 [01:22<00:00,  1.33s/batch, train_loss=0.0394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training RMSE: 0.1543, Validation RMSE: 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████████████████████████████████| 62/62 [01:22<00:00,  1.33s/batch, train_loss=0.0117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training RMSE: 0.1538, Validation RMSE: 0.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████| 62/62 [01:22<00:00,  1.33s/batch, train_loss=0.0454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training RMSE: 0.1545, Validation RMSE: 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████████████████████████████████| 62/62 [01:22<00:00,  1.33s/batch, train_loss=0.0300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Training RMSE: 0.1541, Validation RMSE: 0.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  87%|█████████████████████████████████████████▊      | 54/62 [01:11<00:10,  1.35s/batch, train_loss=0.0310]"
     ]
    }
   ],
   "source": [
    "# Crear una instancia del modelo\n",
    "model = ModelParallel()\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99)\n",
    "#optimizer = torch.optim.Adagrad(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "## ENTRENAR MODELO ###\n",
    "print(\"\\n READY TO TRAIN THE MODEL______________________\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "train_summaries = []\n",
    "training_times = []\n",
    "valid_summaries = []\n",
    "test_summaries = []\n",
    "start_time_tot = time.time()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    liberar_memoria()\n",
    "    #print(\"\\n \\n Antes:\")\n",
    "    #os.system('nvidia-smi')\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\") as progress_bar:\n",
    "        for images, velocities in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images.to('cuda:0')).to('cuda:3')\n",
    "            loss = criterion(outputs, velocities.to('cuda:3'))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix(train_loss=f\"{loss.item():.4f}\")\n",
    "            progress_bar.update()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_rmse = math.sqrt(train_loss)  # Calcular RMSE a partir de MSE\n",
    "    train_summaries.append(train_rmse)\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, velocities in valid_loader:\n",
    "            outputs = model(images.to('cuda:0')).to('cuda:3')\n",
    "            loss = criterion(outputs, velocities.to('cuda:3'))\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    valid_loss /= len(valid_loader)\n",
    "    valid_rmse = math.sqrt(valid_loss)  # Calcular RMSE a partir de MSE\n",
    "    valid_summaries.append(valid_rmse)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training RMSE: {train_rmse:.4f}, Validation RMSE: {valid_rmse:.4f}\")\n",
    "\n",
    "    #print(\"\\n \\n Despues:\")\n",
    "    #os.system('nvidia-smi')\n",
    "    end_time = time.time()\n",
    "    training_times.append(end_time - start_time)\n",
    "        \n",
    "# Evaluar en el conjunto de prueba\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_loader), desc=\"Testing\", unit=\"batch\") as progress_bar:\n",
    "        for images, velocities in test_loader:\n",
    "            outputs = model(images.to('cuda:0')).to('cuda:3')\n",
    "            loss = criterion(outputs, velocities.to('cuda:3'))\n",
    "            test_loss += loss.item()\n",
    "            progress_bar.set_postfix(test_loss=f\"{loss.item():.4f}\")\n",
    "            progress_bar.update()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_rmse = math.sqrt(test_loss)  # Calcular RMSE a partir de MSE\n",
    "    test_summaries.append(test_rmse)\n",
    "    \n",
    "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# Guardar los resúmenes de entrenamiento, validación y prueba\n",
    "with open('train_summaries.txt', 'w') as f:\n",
    "    for epoch, loss in enumerate(train_summaries, 1):\n",
    "        f.write(f\"Epoch {epoch}, Training RMSE: {loss:.4f}\\n\")\n",
    "\n",
    "with open('valid_summaries.txt', 'w') as f:\n",
    "    for epoch, loss in enumerate(valid_summaries, 1):\n",
    "        f.write(f\"Epoch {epoch}, Validation RMSE: {loss:.4f}\\n\")\n",
    "\n",
    "with open('test_summaries.txt', 'w') as f:\n",
    "    for epoch, loss in enumerate(test_summaries, 1):\n",
    "        f.write(f\"Epoch {epoch}, Test RMSE: {loss:.4f}\\n\")\n",
    "\n",
    "\n",
    "# Guardar modelo\n",
    "npix = 300\n",
    "ntn = len(train_images)\n",
    "nv = len(valid_images)\n",
    "ntt = len(test_images)\n",
    "model_name = f'modelo_npix{npix}_ntn{ntn}_nv{nv}_ntt{ntt}_b{batch}_ts{time_steps}.pth'\n",
    "torch.save(model.state_dict(), model_name)\n",
    "\n",
    "end_time_tot = time.time()\n",
    "print(end_time_tot - start_time_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc4380-b318-4e6a-896d-bd3cfecc336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar pérdidas\n",
    "epochs_range = range(1, epochs + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs_range, train_summaries, label='Training RMSE')\n",
    "plt.plot(epochs_range, valid_summaries, label='Validation RMSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training and Validation RMSE per Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('rmse_per_epoch.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9bea0-88a9-40a3-9b7a-f920c1665af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(image_data):\n",
    "    plt.figure()\n",
    "    plt.imshow(image_data)\n",
    "    plt.colorbar()\n",
    "    plt.title('Imagen FITS')\n",
    "    plt.xlabel('Pixel X')\n",
    "    plt.ylabel('Pixel Y')\n",
    "    plt.gca().invert_yaxis() \n",
    "    plt.savefig('Image-disk.png')\n",
    "    plt.show()\n",
    "\n",
    "def plotVelocity(v_real, v_model, pix):\n",
    "\n",
    "    x = np.linspace(0, 300, pix)\n",
    "    y = np.linspace(0, 300, pix)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.pcolormesh(X, Y, v_real)\n",
    "    plt.colorbar(label='Velocidad FARGO3D')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Componente de Velocidad según FARGO3D')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pcolormesh(X, Y, v_model)\n",
    "    plt.colorbar(label='Velocidad Model')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Componente de Velocidad según Model')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Velocity-result-comparison.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9919c8b-6856-4549-ab56-3182b4e669e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Cargar el modelo entrenado para pruebas unitarias\n",
    "model_name = 'modelo_npix300_ntn123_nv82_ntt11_b2_ts14.pth'\n",
    "model = ModelParallel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.load_state_dict(torch.load(model_name), strict=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1457195-bdd1-4763-ad1a-58d639090286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar visualmente los resultados\n",
    "model.eval()\n",
    "all_predictions = np.empty((0, *(npix, npix, 1)))\n",
    "all_real = np.empty((0, *(npix, npix, 1)))\n",
    "all_test_images = np.empty((0, *(14, npix, npix, 1)))\n",
    "# Hacer predicciones\n",
    "with torch.no_grad():\n",
    "    for i, (images, velocities) in enumerate(test_loader):\n",
    "        predicciones = model(images.to('cuda:0'))\n",
    "        #predicciones = predicciones[np.newaxis, :, :, :]\n",
    "        if predicciones.shape != torch.Size([batch, 300, 300, 1]):\n",
    "            print(f\"Ignoring prediction at index {i} with shape {predicciones.shape}\")\n",
    "            continue\n",
    "        loss = criterion(predicciones.to('cuda:3'), velocities.to('cuda:3'))\n",
    "        all_predictions = np.append(all_predictions, predicciones.cpu().numpy(), axis=0)\n",
    "        all_real = np.append(all_real, velocities.cpu().numpy(), axis=0)\n",
    "        all_test_images = np.append(all_test_images, images.cpu().numpy(), axis=0)\n",
    "\n",
    "print(all_predictions.shape)\n",
    "print(all_real.shape)\n",
    "print(all_test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e22a3-d006-419c-8901-befb7f70c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "plotImage(all_test_images[id][9].reshape((300, 300)))\n",
    "plotVelocity(all_real[id].reshape((300, 300)), all_predictions[id].reshape((300,300)), 300)\n",
    "y_true = all_real[id].reshape((300, 300))\n",
    "y_pred = all_predictions[id].reshape((300,300))\n",
    "\n",
    "# Calcular RMSE\n",
    "mse = np.mean((y_true - y_pred) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Calcular MAE\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Calcular SSIM\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "ssim_index, _ = ssim(y_true, y_pred, data_range=y_true.max() - y_true.min(), full=True)\n",
    "print(f\"SSIM: {ssim_index:.4f}\")\n",
    "\n",
    "# Calcular el mapa de errores\n",
    "error_map = np.abs(y_true - y_pred)\n",
    "\n",
    "# Visualizar el mapa de errores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(error_map, cmap='inferno', interpolation='nearest')\n",
    "plt.colorbar(label='Error Absoluto')\n",
    "plt.title('Mapa de Errores')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.savefig('Error_Map.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
